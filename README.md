# DL_learn
这是一个个人的学习记录，记录本人从小白开始学习深度学习的过程和过程中产生的一些代码、文档等。
## 25/03/17 ResNet网络
aMyResNet.ipynb记录了我写出的第一个神经网络代码。

在写代码的过程中有种知其然不知所以然的感觉。直到代码每个部分应该写些什么，但是不知道该怎么写，只能对着现有代码一点点模仿着写。目前的话，对于数据处理部分的代码比较模糊。后面需要加强动手敲代码的能力。

## 25/05/05 线性回归
linear_regression.py记录了我写出的第一个线性回归代码。

上面的resnet的代码实话说并不是完全由我自己完成，而是参考了已有的代码，一点点仿照完成的。后面尽量在五月内完成知道LSTM的代码撰写。这些网络的相关原理的学习已经告一段落，撰写这些代码的目的更多是提高自己的实践能力。

## 25/05/06 softmax
softmax.py是我写的第一个softmax代码，实现了一个手写数字识别的模型。

这里学习了他人代码的模块化设计，后续可以在主函数部分只保留相关的核心逻辑，将尽可能多的内容放在模块化定义的函数中。

## 25/05/08 MLP
MLP.py是多层感知机的代码。多层感知机相较于前面的算法，增加了中间的隐藏层和激活函数。

这里增加了GPU的使用，实现更快的运算。

## 25/05/09 LeNet
lenet.py是CNN网络中的LeNet网络的代码。这部分代码发现实际上训练和测试的很多代码是重复的，所以后面的CNN和RNN部分尽可能将网络的定义单独拿出来，放在一个文件里，直接调用。这样会更模块化一些？

新增了**net.py**和**train.py**，net中存放各种网络模型，train这是模型的训练，这样可以将cnn相关的代码整合在一起。后面rnn部分也采用这样的方式。

## 25/05/10 VGG
在net中更新了VGG11和AlexNet的实现，目前体感是CNN后续的很多网络都是对块进行的设计，基本上就是调整相应的块实现即可。

## 25/05/11 NiN
在net中更新了NiN网络的实现，本质上还是块设计。

另外值得注意的是，NiN网络在训练过程中，如果不进行初始化，可能会出现训练效果差的问题。笔者在训练过程中出现了loss和测试准确率不变的情况，在尝试修改学习率、批量大小等之后，发现只需要进行合适的参数初始化即可。
