{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第一部分 python库调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第二部分 数据预处理\n",
    "* RandomHorizontalFlip()：以50%概率水平翻转图像，适合处理对称性图像和数据。对于非对称数据，例如鞋子，可能会产生不真实样本，但是可以提升模型的泛化能力。\n",
    "* RandomCrop(28, padding=4)：在28x28的图像周围填充4个像素，变成36x36，再随机裁剪出28x28的图像。模拟物体位置变化的情况，增强模型对物体位置的鲁棒性。\n",
    "* ToTensor()：将pil图像或者numpy数组转为torch张量，并且自动将像素值从255缩放到1，调整维度为1x28x28.\n",
    "* Normalize()：将[0,1]映射到[-1,1]。标准化数据分布，加速模型收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(28,padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第三部分 ResNet基本模块\n",
    "关键点：\n",
    "* 残差结构：通过'out += self.shortcut(x)'实现跳跃连接，主路径学习残差f(x)=h(x)-x。\n",
    "* 维度匹配：当输入输出通道数不同或需要下采样时，使用1x1卷积调整路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义ResNet基本模块（残差块）\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1 # 通道扩展系数，用于控制输出通道数\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__() # 调用父类nn.Module的初始化方法\n",
    "\n",
    "        # 第一个卷积层（3x3）\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size = 3,\n",
    "            stride = stride, # 步长为1，保持原始尺寸\n",
    "            padding = 1, # 填充为1，在3x3卷积下，保持尺寸不变\n",
    "            bias = False\n",
    "        )\n",
    "\n",
    "        # 第一个批量归一化层\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 第二个卷积层（3x3）\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size = 3,\n",
    "            stride = 1,\n",
    "            padding = 1,\n",
    "            bias = False\n",
    "        )\n",
    "\n",
    "        # 第二个批量归一化层\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 捷径连接\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        # 如果输入通道数与输出通道数不一致，需要调整捷径连接\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    self.expansion * out_channels,\n",
    "                    kernel_size = 1,\n",
    "                    stride = stride,\n",
    "                    bias = False\n",
    "                ),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 主路径\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        # 残差连接：主路径+捷径路径\n",
    "        out += self.shortcut(x)\n",
    "\n",
    "        # 最终激活\n",
    "        out = torch.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第四部分 定义完整的ResNet网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64 # 初始化输入通道数\n",
    "\n",
    "        # 初始卷积层\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            1, #输入通道为1，适应mnist\n",
    "            64, #输出通道为64\n",
    "            kernel_size = 3,\n",
    "            stride = 1,\n",
    "            padding = 1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64) # 64通道的批量归一化层\n",
    "\n",
    "        # 四个层级，对应不同空间尺度\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1) #尺度维持\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2) #下采样\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2) #下采样\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2) #下采样\n",
    "\n",
    "        # 全局平均赤化层，将特征图片压缩到1x1\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        \"\"\" 构建包含多个残差块的层级\n",
    "        Args:\n",
    "            block:     残差块类型（BasicBlock/Bottleneck）\n",
    "            out_channels: 该层目标输出通道数\n",
    "            num_blocks:   该层包含的残差块数量\n",
    "            stride:       第一个残差块的步长（控制下采样）\n",
    "        \"\"\"\n",
    "        # 生成步长列表，仅第一个块可能下采样\n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "\n",
    "        layers = [] # 保存该层所有残差块\n",
    "        for stride in strides:\n",
    "            # 创建残差块实例\n",
    "            layers.append(block(\n",
    "                self.in_channels,\n",
    "                out_channels,\n",
    "                stride\n",
    "            ))\n",
    "            # 更新下一个残差块的输入通道数\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        # 返回该层\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    # 前向传播\n",
    "    def forward(self, x):\n",
    "        # 初始卷积+bn+relu\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        # 通过4个layer\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        # 全局平均池化\n",
    "        out = self.avgpool(out)\n",
    "\n",
    "        # 展平层\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # 全连接层\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出测试\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet(BasicBlock, [2, 2, 2, 2]).to(device)\n",
    "x = model(x.to(device))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第五部分 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train(model, device, trainloader, optimizer, criterion, epoch):\n",
    "    # 设置模型为训练模式\n",
    "    model.train()\n",
    "    # 初始化累计损失和正确预测数\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    # 设置进度条\n",
    "    progress_bar = tqdm(trainloader, desc=f'Epoch {epoch}')\n",
    "\n",
    "    # 遍历数据加载器，每次迭代获取一个batch\n",
    "    for inputs, targets in progress_bar:\n",
    "        # 将数据移动到指定设备\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, targets)\n",
    "        # 反向传播：计算梯度（链式法则）\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累加损失\n",
    "        total_loss += loss.item()\n",
    "        # 计算预测值（dim=1取每行最大值索引）\n",
    "        _, predicted = outputs.max(dim=1)\n",
    "        # 累加正确预测数（eq比较预测与真实标签，sum求和）\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # 更新进度条显示信息\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f\"{total_loss/(progress_bar.n+1):.3f}\",\n",
    "            'Acc': f\"{100.*correct/((progress_bar.n+1)*inputs.size(0)):.1f}%\"\n",
    "        })\n",
    "    # 返回：平均损失（总损失/总batch数），总体准确率（正确数/总样本数）\n",
    "    return total_loss / len(trainloader), correct / len(trainloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第六部分 测试函数\n",
    "值得注意，这里使用no_grad()，禁用梯度计算（节省内存，提升推理速度）。这在测试过程中是值得的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, testloader, criterion):\n",
    "    # 将模型设置为评估模式\n",
    "    model.eval()\n",
    "    # 初始化损失和正确预测数\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # 禁用梯度计算（节省内存，提升推理速度）\n",
    "    with torch.no_grad():\n",
    "        # 遍历测试数据\n",
    "        for inputs, targets in testloader:\n",
    "            # 将数据移动到指定设备\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            # 前向传播\n",
    "            outputs = model(inputs)\n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, targets)\n",
    "            # 累加损失\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(dim=1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100. * correct / len(testloader.dataset)\n",
    "    print(f'\\nTest Loss: {total_loss/len(testloader):.3f}, Test Acc: {acc:.1f}%')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第七部分 主函数\n",
    "主函数部分主要包含以下几个部分：\n",
    "* 参数配置：配置一些全局公用的参数，例如batch_size等。\n",
    "* 加载数据：进行数据集的加载。\n",
    "* 模型初始化：设置初始化的模型，定义损失函数、优化器等。\n",
    "* 训练循环\n",
    "\n",
    "这里对scheduler动态调整学习率进行简单介绍。其核心参数如下：\n",
    "* optimizer：绑定的优化器对象（如Adam/SGD）\n",
    "* mode：监控指标的优化方向：'max'（越大越好，如准确率）或 'min'（越小越好，如损失）\n",
    "* patience：触发学习率降低前允许指标停滞的epoch数\n",
    "* factor (默认0.1)：学习率缩放因子（新LR = 旧LR × factor）\n",
    "* threshold (默认1e-4)：指标变化的阈值（超过此值才视为\"提升\"）\n",
    "* min_lr (默认0)：学习率下限（LR不会低于此值）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 235/235 [00:12<00:00, 18.80it/s, Loss=0.592, Acc=209.4%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.386, Test Acc: 86.3%\n",
      "New best model saved! Accuracy: 86.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 235/235 [00:12<00:00, 19.49it/s, Loss=0.361, Acc=231.6%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.331, Test Acc: 88.1%\n",
      "New best model saved! Accuracy: 88.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 235/235 [00:12<00:00, 19.48it/s, Loss=0.308, Acc=235.9%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.443, Test Acc: 83.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 235/235 [00:12<00:00, 19.29it/s, Loss=0.277, Acc=238.9%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.366, Test Acc: 87.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 235/235 [00:12<00:00, 19.07it/s, Loss=0.261, Acc=241.6%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.367, Test Acc: 85.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 235/235 [00:11<00:00, 19.79it/s, Loss=0.249, Acc=244.1%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.372, Test Acc: 86.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 235/235 [00:11<00:00, 20.01it/s, Loss=0.197, Acc=249.4%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.197, Test Acc: 92.9%\n",
      "New best model saved! Accuracy: 92.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 235/235 [00:11<00:00, 19.92it/s, Loss=0.179, Acc=248.9%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.197, Test Acc: 93.0%\n",
      "New best model saved! Accuracy: 92.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 235/235 [00:11<00:00, 19.87it/s, Loss=0.175, Acc=250.4%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.194, Test Acc: 93.4%\n",
      "New best model saved! Accuracy: 93.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 235/235 [00:11<00:00, 19.78it/s, Loss=0.171, Acc=251.7%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.186, Test Acc: 93.5%\n",
      "New best model saved! Accuracy: 93.52%\n",
      "\n",
      "Final Best Accuracy: 93.52%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 配置参数\n",
    "    batch_size = 256 # 每个批次包含256个样本\n",
    "    num_workers = 0 # 加载数据的子进程数,Windows必须为0，其他系统可以设置为cpu核心数\n",
    "\n",
    "    # 数据加载\n",
    "    # 训练集配置\n",
    "    trainset = torchvision.datasets.FashionMNIST(\n",
    "        root = './data',\n",
    "        train = True, # 加载训练集\n",
    "        download = True, # 自动下载数据集\n",
    "        transform = train_transform # 训练数据增强，需要提前定义，包含随机翻转、裁剪等\n",
    "    )\n",
    "    trainloader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True, # 打乱数据顺序\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "\n",
    "    # 测试集配置\n",
    "    testset = torchvision.datasets.FashionMNIST(\n",
    "        root = './data',\n",
    "        train = False,\n",
    "        download = True,\n",
    "        transform = test_transform\n",
    "    )\n",
    "    testloader = DataLoader(\n",
    "        testset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = False, # 不需要打乱数据\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "\n",
    "    # 模型初始化和训练初始化\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 优先使用GPU\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2]).to(device) # 初始化模型\n",
    "    criterion = nn.CrossEntropyLoss() # 损失函数\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.001, # 初始学习率\n",
    "        weight_decay=1e-4 # L2正则化系数（防止过拟合）\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max', # 根据准确率最大化调整学习率\n",
    "        patience=3 # 连续3个epoch指标未提升则降低LR\n",
    "    )\n",
    "\n",
    "    # 训练循环\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(10):\n",
    "        train_loss, train_acc = train(model, device, trainloader, optimizer, criterion, epoch)\n",
    "        test_acc = test(model, device, testloader, criterion)\n",
    "        scheduler.step(test_acc)\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"New best model saved! Accuracy: {best_acc:.2f}%\")\n",
    "\n",
    "    print(f\"\\nFinal Best Accuracy: {best_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
